# -*- coding: utf-8 -*-
"""Viz.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13S1aTCV6-TUDiEEh16g9zX57_rxLcuY6
"""

import re
import pandas as pd

# Default Names
# Note: Change the paths to whatever you wanna compare here!
# William's
fileserver_path = "log_william/fileserver_2023-02-20_22:52:17.log"
oltp_path = "log_william/oltp_2023-02-20_22:52:17.log"
webserver_path = "log_william/webserver_2023-02-20_22:52:17.log"
smallrw_path = "log_william/randomrw_small_2023-02-21_13:45:10.log"
bigrw_path = "log_william/randomrw_big_2023-02-21_13:45:10.log"
smallr_path = "log_william/randomr_small_2023-02-20_22:52:17.log"
bigr_path = "log_william/randomr_big_2023-02-20_22:52:17.log"

# Root's (DO Droplet)
fileserver_path_2 = "log_root/fileserver_2023-02-20_17:10:09.log"
oltp_path_2 = "log_root/oltp_2023-02-20_17:10:09.log"
webserver_path_2 = "log_root/webserver_2023-02-20_17:10:09.log"
smallrw_path_2 = "log_root/randomrw_small_2023-02-21_07:12:13.log"
bigrw_path_2 = "log_root/randomrw_big_2023-02-21_07:12:13.log"
smallr_path_2 = "log_root/randomr_small_2023-02-21_12:13:37.log"
bigr_path_2 = "log_root/randomr_big_2023-02-21_12:13:37.log"

# Constants for graph information
measured_metrics = ["Sum of all I/O and Async I/O flowop executions", "Overall I/O throughput", "Number of reads", "Number of writes", "Overall throughput of all I/O flowops", "Overall latency of all I/O flowops"]
units = ["I/O Operations (ops)", "I/O Ops Throughput (ops/s)", "Reads (ops)", "Writes (ops)", "Throughput (mb/s)", "Latency (ms/op)"]
file_name = ["Flowops Exec", "IO Throughput", "Reads", "Writes", "Throughput", "Latency"]

## Split log file and only extract the lines containing summary (the good stuff).
## Returns array of lines containing IO Summary
def split_IO_summary(file_path):
  IO_sum_arr = []
  with open(file_path, "r") as file:
      for line in file:
          if "IO Summary" in line:
            IO_sum_arr.append(line)
  return IO_sum_arr

## Tokenize Data in IO summary, put them in their respective category according to index.
## Returns array of dict containing data for the given log.
def process_IO_summary(IO_sum_arr):
  pattern = r"\d+\.?\d*"

  io_sum = {"time" :[], "value": []}
  io_throughput = {"time" :[], "value": []}
  reads = {"time" :[], "value": []}
  writes = {"time" :[], "value": []}
  throughput = {"time" :[], "value": []}
  io_latency = {"time" :[], "value": []}

  arr_dict = [io_sum, io_throughput, reads, writes, throughput, io_latency]
  for log in IO_sum_arr:
    index = 0
    time = 0
    for token in log.split(" "):
      matches = re.findall(pattern, token)
      for num in matches:
        if index == 0:
          time = num
        else:
          arr_dict[index-1]["time"].append(float(time))
          arr_dict[index-1]["value"].append(float(num))
        index += 1

  return arr_dict

## Plot difference between 2 dicts.
## Permanently display on screen.
def plot_diff(my_data, do_data, test_type):

  for i in range(len(my_data)):
    df = pd.DataFrame(my_data[i])
    df.rename(columns={'value': 'My Computer'}, inplace=True)
    df.set_index("time", inplace=True)
    
    ax = df.plot()

    df2 = pd.DataFrame(do_data[i])
    df2.rename(columns={'value': 'DO Droplet'}, inplace=True)
    df2.set_index("time", inplace=True)
    ax2 = df2.plot(ax=ax)

    ## Give labels according to index of dict
    ax2.set_ylabel(units[i])
    ax2.set_title(test_type + "\n" + measured_metrics[i])
    ax2.set_xlabel('Time (s)')

    figure_name = (test_type + file_name[i]).replace(" ", "")
    ax2.get_figure().savefig("bin/"+figure_name)
    # display.display(df2)
    # display.clear_output(wait=True)

"""#Random Read Writes on Small Dataset"""

res_1 = process_IO_summary(split_IO_summary(smallrw_path))
res_2 = process_IO_summary(split_IO_summary(smallrw_path_2))
plot_diff(res_1, res_2, "SmallRandomRW")

"""#Random Reads on Big Data (5 GiB)"""

res_1 = process_IO_summary(split_IO_summary(bigrw_path))
res_2 = process_IO_summary(split_IO_summary(bigrw_path_2))
plot_diff(res_1, res_2, "BigRandomRW")

"""#OLTP Workload"""

res_1 = process_IO_summary(split_IO_summary(oltp_path))
res_2 = process_IO_summary(split_IO_summary(oltp_path_2))
plot_diff(res_1, res_2, "OLTP")

"""#Webserver Workload"""

res_1 = process_IO_summary(split_IO_summary(webserver_path))
res_2 = process_IO_summary(split_IO_summary(webserver_path_2))
plot_diff(res_1, res_2, "Web Server")

"""#Fileserver workload"""

res_1 = process_IO_summary(split_IO_summary(fileserver_path))
res_2 = process_IO_summary(split_IO_summary(fileserver_path_2))
plot_diff(res_1, res_2, "File Server")

"""#Small Random Read"""
res_1 = process_IO_summary(split_IO_summary(smallr_path))
res_2 = process_IO_summary(split_IO_summary(smallr_path_2))
plot_diff(res_1, res_2, "Small Random Read")

"""#Big Random Read"""
res_1 = process_IO_summary(split_IO_summary(bigr_path))
res_2 = process_IO_summary(split_IO_summary(bigr_path_2))
plot_diff(res_1, res_2, "Big Random Read")